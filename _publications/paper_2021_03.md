---
title: "Multi-Interactive Dual-Decoder for RGB-Thermal Salient Object Detection (TIP 2021)"
collection: publications
permalink: /publication/paper_2021_03
excerpt: "**Zhengzheng Tu**, Zhun Li, Chenglong Li, Yang Lang, Jin Tang"
# date: 2009-10-01
# venue: "Journal 1"
# slidesurl: "http://academicpages.github.io/files/slides1.pdf"
# paperurl: "http://academicpages.github.io/files/paper1.pdf"
# citation: "Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1)."
---

**Zhengzheng Tu**, Zhun Li, Chenglong Li, Yang Lang, Jin Tang

**Abstract:** RGB-thermal salient object detection (SOD) aims to segment the common prominent regions of visible image and corresponding thermal infrared image that we call it RGBT SOD. Existing methods don't fully explore and exploit the potentials of complementarity of different modalities and multi-type cues of image contents, which play a vital role in achieving accurate results. In this paper, we propose a multi-interactive dual-decoder to mine and model the multi-type interactions for accurate RGBT SOD. In specific, we first encode two modalities into multi-level multi-modal feature representations. Then, we design a novel dual-decoder to conduct the interactions of multi-level features, two modalities and global contexts. With these interactions, our method works well in diversely challenging scenarios even in the presence of invalid modality. Finally, we carry out extensive experiments on public RGBT and RGBD SOD datasets, and the results show that the proposed method achieves the outstanding performance against state-of-the-art algorithms. The source code has been released at: https://github.com/lz118/Multi-interactive-Dual-decoder.

**DOI:** https://ieeexplore.ieee.org/document/9454273
