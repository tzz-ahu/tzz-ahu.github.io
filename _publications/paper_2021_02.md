---
title: "M5L: Multi-Modal Multi-Margin Metric Learning for RGBT Tracking (TIP 2021)"
collection: publications
permalink: /publication/paper_2021_02
excerpt: "**Zhengzheng Tu**, Chun Lin, Wei Zhao, Chenglong Li, Jin Tang"
# date: 2009-10-01
# venue: "Journal 1"
# slidesurl: "http://academicpages.github.io/files/slides1.pdf"
# paperurl: "http://academicpages.github.io/files/paper1.pdf"
# citation: "Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1)."
---

**Zhengzheng Tu**, Chun Lin, Wei Zhao, Chenglong Li, Jin Tang

**Abstract:** Classifying hard samples in the course of RGBT tracking is a quite challenging problem. Existing methods only focus on enlarging the boundary between positive and negative samples, but ignore the relations of multilevel hard samples, which are crucial for the robustness of hard sample classification. To handle this problem, we propose a novel Multi-Modal Multi-Margin Metric Learning framework named M 5 L for RGBT tracking. In particular, we divided all samples into four parts including normal positive, normal negative, hard positive and hard negative ones, and aim to leverage their relations to improve the robustness of feature embeddings, e.g., normal positive samples are closer to the ground truth than hard positive ones. To this end, we design a multi-modal multi-margin structural loss to preserve the relations of multilevel hard samples in the training stage. In addition, we introduce an attention-based fusion module to achieve quality-aware integration of different source data. Extensive experiments on large-scale datasets testify that our framework clearly improves the tracking performance and performs favorably the state-of-the-art RGBT trackers.

**DOI:** https://ieeexplore.ieee.org/document/9617143
