---
title: "TriTransNet: RGB-D Salient Object Detection with a Triplet Transformer Embedding Network (ACM MM 2021)"
collection: publications
permalink: /publication/paper_2021_04
excerpt: "Zhengyi Liu, Yuan Wang, **Zhengzheng Tu**, Yun Xiao, and Bin Tang"
# date: 2009-10-01
# venue: "Journal 1"
# slidesurl: "http://academicpages.github.io/files/slides1.pdf"
# paperurl: "http://academicpages.github.io/files/paper1.pdf"
# citation: "Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1)."
---

Zhengyi Liu, Yuan Wang, **Zhengzheng Tu**, Yun Xiao, and Bin Tang

**Abstract:** Salient object detection is the pixel-level dense prediction task which can highlight the prominent object in the scene. Recently U-Net framework is widely used, and continuous convolution and pooling operations generate multi-level features which are complementary with each other. In view of the more contribution of high-level features for the performance, we propose a triplet transformer embedding module to enhance them by learning long-range dependencies across layers. It is the first to use three transformer encoders with shared weights to enhance multi-level features. By further designing scale adjustment module to process the input, devising three-stream decoder to process the output and attaching depth features to color features for the multi-modal fusion, the proposed triplet transformer embedding network (TriTransNet) achieves the state-of-the-art performance in RGB-D salient object detection, and pushes the performance to a new level. Experimental results demonstrate the effectiveness of the proposed modules and the competition of TriTransNet.

**DOI:** https://dl.acm.org/doi/abs/10.1145/3474085.3475601
