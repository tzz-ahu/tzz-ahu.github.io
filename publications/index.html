<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=2"
    />
    <meta name="theme-color" content="#222" />
    <meta name="generator" content="Hexo 5.4.0" />

    <link
      rel="apple-touch-icon"
      sizes="180x180"
      href="/images/apple-touch-icon-next.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="32x32"
      href="/images/favicon-32x32-next.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="16x16"
      href="/images/favicon-16x16-next.png"
    />
    <link rel="mask-icon" href="/images/logo.svg" color="#222" />

    <link rel="stylesheet" href="/css/main.css" />

    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css"
      integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y="
      crossorigin="anonymous"
    />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css"
      integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE="
      crossorigin="anonymous"
    />

    <script class="next-config" data-name="main" type="application/json">
      {&quot;hostname&quot;:&quot;example.com&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Gemini&quot;,&quot;version&quot;:&quot;8.5.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:false,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;Searching...&quot;,&quot;empty&quot;:&quot;We didn&#39;t find any results for the search: ${query}&quot;,&quot;hits_time&quot;:&quot;${hits} results found in ${time} ms&quot;,&quot;hits&quot;:&quot;${hits} results found&quot;}}
    </script>
    <script src="/js/config.js"></script>
    <meta name="description" content="" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Publications" />
    <meta
      property="og:url"
      content="http://example.com/publications/index.html"
    />
    <meta property="og:site_name" content="Zhengzheng Tu&#39;s Page" />
    <meta property="og:description" content="" />
    <meta property="og:locale" content="en_US" />
    <meta
      property="article:published_time"
      content="2024-05-11T03:20:23.930Z"
    />
    <meta property="article:modified_time" content="2024-05-11T03:20:23.930Z" />
    <meta property="article:author" content="Zhengzheng Tu" />
    <meta name="twitter:card" content="summary" />

    <link rel="canonical" href="http://example.com/publications/" />

    <script class="next-config" data-name="page" type="application/json">
      {&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:false,&quot;isPost&quot;:false,&quot;lang&quot;:&quot;en&quot;,&quot;comments&quot;:true,&quot;permalink&quot;:&quot;http:&#x2F;&#x2F;example.com&#x2F;publications&#x2F;index.html&quot;,&quot;path&quot;:&quot;publications&#x2F;index.html&quot;,&quot;title&quot;:&quot;Publications&quot;}
    </script>

    <script class="next-config" data-name="calendar" type="application/json">
      &quot;&quot;
    </script>
    <title>Zhengzheng Tu' Page</title>

    <noscript>
      <link rel="stylesheet" href="/css/noscript.css" />
    </noscript>
  </head>

  <body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
    <div class="headband"></div>

    <main class="main">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader">
        <div class="header-inner">
          <div class="site-brand-container">
            <div class="site-nav-toggle">
              <div
                class="toggle"
                aria-label="Toggle navigation bar"
                role="button"
              >
                <span class="toggle-line"></span>
                <span class="toggle-line"></span>
                <span class="toggle-line"></span>
              </div>
            </div>

            <div class="site-meta">
              <a href="/" class="brand" rel="start">
                <i class="logo-line"></i>
                <h1 class="site-title">Zhengzheng Tu</h1>
                <i class="logo-line"></i>
              </a>
            </div>

            <div class="site-nav-right">
              <div class="toggle popup-trigger"></div>
            </div>
          </div>

          <nav class="site-nav">
            <ul class="main-menu menu">
              <li class="menu-item menu-item-home">
                <a href="/" rel="section"
                  ><i class="fa fa-home fa-fw"></i>Home</a
                >
              </li>
              <li class="menu-item menu-item-publications">
                <a href="/publications/" rel="section"
                  ><i class="fa fa-file fa-fw"></i>Publications</a
                >
              </li>
              <li class="menu-item menu-item-patents">
                <a href="/patents" rel="section"
                  ><i class="fa fa-book fa-fw"></i>Patents</a
                >
              </li>
              <li class="menu-item menu-item-projects">
                <a href="/projects/" rel="section"
                  ><i class="fa fa-clipboard fa-fw"></i>Projects</a
                >
              </li>
              <li class="menu-item menu-item-award">
                <a href="/award/" rel="section"
                  ><i class="fa fa-gift fa-fw"></i>Award</a
                >
              </li>
              <li class="menu-item menu-item-achievements">
                <a href="/achievements/" rel="section"
                  ><i class="fa fa-archive fa-fw"></i>Achievements</a
                >
              </li>
              <li class="menu-item menu-item-cultivation">
                <a href="/cultivation/" rel="section"
                  ><i class="fa fa-graduation-cap fa-fw"></i>Cultivation</a
                >
              </li>
            </ul>
          </nav>
        </div>

        <div class="toggle sidebar-toggle" role="button">
          <span class="toggle-line"></span>
          <span class="toggle-line"></span>
          <span class="toggle-line"></span>
        </div>

        <aside class="sidebar">
          <div class="sidebar-inner sidebar-overview-active">
            <ul class="sidebar-nav">
              <li class="sidebar-nav-toc">Table of Contents</li>
              <li class="sidebar-nav-overview">Overview</li>
            </ul>

            <div class="sidebar-panel-container">
              <!--noindex-->
              <div class="post-toc-wrap sidebar-panel"></div>
              <!--/noindex-->

              <div class="site-overview-wrap sidebar-panel">
                <div
                  class="site-author site-overview-item animated"
                  itemprop="author"
                  itemscope
                  itemtype="http://schema.org/Person"
                >
                  <img
                    class="site-author-image"
                    itemprop="image"
                    alt="Zhengzheng Tu"
                    src="/images/profile.png"
                  />
                  <p class="site-author-name" itemprop="name">Zhengzheng Tu</p>
                  <div class="site-description" itemprop="description"></div>
                </div>
                <div class="links-of-author site-overview-item animated">
                  <span class="links-of-author-item">
                    <a
                      href="https://github.com/tzz-ahu"
                      title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;tzz-ahu"
                      rel="noopener"
                      target="_blank"
                      ><i class="fab fa-github fa-fw"></i>GitHub</a
                    >
                  </span>
                  <span class="links-of-author-item">
                    <a
                      href="mailto:zhengzhengahu@163.com"
                      title="E-Mail → mailto:zhengzhengahu@163.com"
                      rel="noopener"
                      target="_blank"
                      ><i class="fa fa-envelope fa-fw"></i>E-Mail</a
                    >
                  </span>
                </div>
              </div>
            </div>
          </div>
        </aside>
        <div class="sidebar-dimmer"></div>
      </header>

      <div class="back-to-top" role="button" aria-label="Back to top">
        <i class="fa fa-arrow-up"></i>
        <span>0%</span>
      </div>

      <noscript>
        <div class="noscript-warning">
          Theme NexT works best with JavaScript enabled
        </div>
      </noscript>

      <div class="main-inner page posts-expand">
        <div class="post-block" lang="en">
          <header class="post-header">
            <h1 class="post-title" itemprop="name headline">Publications</h1>

            <div class="post-meta-container"></div>
          </header>

          <div class="post-body">
            <!-- ## Preprint -->
            <h2 id="2024">
              <a href="#2024" class="headerlink" title="2024"></a>2024
            </h2>
            <p>
              [1] Chuang Chen, Xiao Sun, <strong>Zhengzheng Tu</strong>, Meng
              Wang. AST-GCN: Augmented Spatial Temporal Graph Convolutional
              Neural Network for Gait Emotion Recognition. (<strong
                >TCSVT 2024</strong
              >)
              <a
                href="publications\pdf\2024\AST-GCN_Augmented_Spatial_Temporal_Graph_Convolutional_Neural_Network_for_Gait_Emotion_Recognition.pdf"
                >[PDF]</a
              >
            </p>

            <p>
              [2] Yuhao Wang, Xuehu Liu, Pingping Zhang, Hu Lu,
              <strong>Zhengzheng Tu</strong>, Huchuan Lu. TOP-ReID:
              Multi-Spectral Object Re-identification with Token Permutation.
              (<strong>AAAI 2024</strong>)

              <a
                href="publications\pdf\2024\TOP-ReID_Multi-spectral_Object_Re-Identification_with_Token_Permutation.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [3] Pingping Zhang, Yuhao Wang, Yang Liu,
              <strong>Zhengzheng Tu</strong>, Huchuan Lu. Magic Tokens: Select
              Diverse Tokens for Multi-modal Object Re-Identification. (<strong
                >CVPR 2024</strong
              >)

              <a
                href="publications\pdf\2024\Zhang_Magic_Tokens_Select_Diverse_Tokens_for_Multi-modal_Object_Re-Identification_CVPR_2024_paper.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [4] Kunpeng Wang, Danying Lin, Chenglong Li,
              <strong>Zhengzheng Tu</strong>, Bin Luo. Alignment-Free RGBT
              Salient Object Detection: Semantics-guided Asymmetric Correlation
              Network and A Unified Benchmark. (<strong>TMM 2024</strong>)

              <a
                href="publications\pdf\2024\Alignment-Free_RGBT_Salient_Object_Detection_Semantics-Guided_Asymmetric_Correlation_Network_and_a_Unified_Benchmark.pdf"
                >[PDF]</a
              >

              <a
                target="_blank"
                rel="noopener"
                href="https://github.com/Angknpng/SACNet"
                >[CODE]</a
              >
            </p>
            <p>
              [5] Kunpeng Wang, <strong>Zhengzheng Tu</strong>, Chenglong Li,
              Cheng Zhang, Bin Luo. Learning Adaptive Fusion Bank for
              Multi-modal Salient Object Detection. (<strong>TCSVT 2024</strong
              >)
            </p>

            <h2 id="2023">
              <a href="#2023" class="headerlink" title="2023"></a>2023
            </h2>

            <p>
              [1] <strong>Zhengzheng Tu</strong>, Wenfang Yang, Kunpeng Wang,
              Amir Hussain, Bin Luo, Chenglong Li. Multimodal salient object
              detection via adversarial learning with collaborative generator.
              (<strong>EAAI 2023</strong>)

              <a
                href="publications\pdf\2023\Multimodal_Salient_Object_Detection_via_Adversarial_Learning_with_Collaborative_Generator.pdf"
                >[PDF]</a
              >
            </p>

            <p>
              [2] Yingyuan Zhao, Zhiyi Tan, Bing-Kun Bao,
              <strong>Zhengzheng Tu</strong>. Centralized sub-critic based
              hierarchical-structured reinforcement learning for temporal
              sentence grounding. (<strong>MMS 2023</strong>)

              <a
                href="publications\pdf\2023\Centralized_sub-critic_based_hierarchical-structured_reinforcement_learning_for_temporal_sentence_grounding.pdf"
                >[PDF]</a
              >
            </p>

            <p>
              [3] <strong>Zhengzheng Tu</strong>, Yan Ma, Zhun Li, Chenglong Li,
              Jieming Xu, Yongtao Liu. RGBT Salient Object Detection: A
              Large-Scale Dataset and Benchmark. (<strong>TMM 2023</strong>)

              <a
                href="publications\pdf\2023\RGBT_Salient_Object_Detection_A_Large-Scale_Dataset_and_Benchmark.pdf"
                >[PDF]</a
              >
            </p>

            <h2 id="2022">
              <a href="#2022" class="headerlink" title="2022"></a>2022
            </h2>

            <p>
              [1] <strong>Zhengzheng Tu</strong>, Wenli Pan, Yunsheng Duan, Jin
              Tang, Chenglong Li. RGBT tracking via reliable feature
              configuration. (<strong>SCIS 2022</strong>)
              <a
                href="publications\pdf\2022\RGBT_tracking_via_reliable_feature_configuration.pdf"
                >[PDF]</a
              >
            </p>

            <p>
              [2] <strong>Zhengzheng Tu</strong>, Chao Wang, Chenglong Li,
              Minghao Fan, Haifeng Zhao, Bin Luo. ORSI Salient Object Detection
              via Multiscale Joint Region and Boundary Model. (<strong
                >TGRS 2022</strong
              >)

              <a
                href="publications\pdf\2022\ORSI_Salient_Object_Detection_via_Multiscale_Joint_Region_and_Boundary_Model.pdf"
                >[PDF]</a
              >
            </p>

            <p>
              [3] <strong>Zhengzheng Tu</strong>, Chun Lin, Wei Zhao, Chenglong
              Li, Jin Tang. M5L: Multi-Modal Multi-Margin Metric Learning for
              RGBT Tracking. (<strong>TIP 2022</strong>)

              <a
                href="publications\pdf\2022\M5L_Multi-Modal_Multi-Margin_Metric_Learning_for_RGBT_Tracking.pdf"
                >[PDF]</a
              >
            </p>

            <p>
              [4] <strong>Zhengzheng Tu</strong>, Zhun Li, Chenglong Li, Jin
              Tang. Weakly Alignment-Free RGBT Salient Object Detection With
              Deep Correlation Network. (<strong>TIP 2022</strong>)

              <a
                href="publications\pdf\2022\Weakly_Alignment-Free_RGBT_Salient_Object_Detection_With_Deep_Correlation_Network.pdf"
                >[PDF]</a
              >
            </p>

            <h2 id="2021">
              <a href="#2021" class="headerlink" title="2021"></a>2021
            </h2>
            <p>
              [1] Zhengzheng Tu, Ajian Zhou, Chuang Gan, Bo Jiang, Amir Hussain,
              Bin Luo. A novel domain activation mapping-guided network (DA-GNT)
              for visual tracking. (<strong>Neurocomputing 2021</strong>)

              <a
                href="publications\pdf\2021\A_novel_domain_activation_mapping-guided_network_(DA-GNT)_for_visual_tracking.pdf"
                >[PDF]</a
              >
            </p>

            <p>
              [2] Zhengzheng Tu, Yan Ma, Chenglong Li, Jin Tang, Bin Luo.
              Edge-Guided Non-Local Fully Convolutional Network for Salient
              Object Detection. (<strong>TCSVT 2021</strong>)

              <a
                href="publications\pdf\2021\Edge-Guided_Non-Local_Fully_Convolutional_Network_for_Salient_Object_Detection.pdf"
                >[PDF]</a
              >
            </p>

            <p>
              [3] Zhengzheng Tu, Zhun Li, Chenglong Li, Yang Lang, Jin Tang.
              Multi-Interactive Dual-Decoder for RGB-Thermal Salient Object
              Detection. (<strong>TIP 2021</strong>)

              <a
                href="publications\pdf\2021\Multi-Interactive_Dual-Decoder_for_RGB-Thermal_Salient_Object_Detection.pdf"
                >[PDF]</a
              >
            </p>

            <p>
              [4] Yi Zhu, Zhengzheng Tu, Shilei Huang, Wanli Lv, Lin Yao.
              Multi-Turn Response Selection Using Business Sequential Relations
              in Traffic Field. (<strong>CIS 2021</strong>)

              <a
                href="publications\pdf\2021\Multi-Turn_Response_Selection_Using_Business_Sequential_Relations_in_Traffic_Field.pdf"
                >[PDF]</a
              >
            </p>

            <p>
              [5] Zhengyi Liu, Yuan Wang, Zhengzheng Tu, Yun Xiao, Bin Tang.
              TriTransNet: RGB-D Salient Object Detection with a Triplet
              Transformer Embedding Network. (<strong>ACM MM 2021</strong>)

              <a
                href="publications\pdf\2021\TriTransNet_RGB-D_Salient_Object_Detection_with_a_Triplet_Transformer_Embedding_Network.pdf"
                >[PDF]</a
              >
            </p>

            <!-- 下面待修改 -->
            <h2 id="2020">
              <a href="#2020" class="headerlink" title="2020"></a>2020
            </h2>
            <p>
              [1] Hongchao Li, Chenglong Li, Xianpeng Zhu,
              <b>Aihua Zheng*</b> &amp; Bin Luo. Multi-spectral Vehicle
              Re-identification: A Challenge[C]//Proceedings of the AAAI
              Conference on Artificial Intelligence. 2020, 34(7): 11345-11353.
              (CCF推荐A类国际会议)<a
                href="pdf/2020/2020-AAAI-Multi-Spectral%20Vehicle%20Re-Identification%20A%20Challe.pdf"
                >[PDF]</a
              ><a
                target="_blank"
                rel="noopener"
                href="https://github.com/aihuazheng/multi-modal-vehicle-Re-ID"
                >[CODE]</a
              >
            </p>
            <p>
              [2] <b>Aihua Zheng</b>, Xuehan Zhang, Bo Jiang, Bin Luo &amp;
              Chenglong Li*. A subspace learning approach to multi-shot person
              re-identification[J]. IEEE Transactions on Systems, Man, and
              Cybernetics: Systems, 2020, 50(1): 149-158. (SCI一区)<a
                href="pdf/2020/2020-TSMCS2020-A%20subspace%20learning%20approach%20to%20multishot%20person%20reidentification.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [3] <b>Aihua Zheng</b>, Hongchao Li, Bo Jiang*, Wei-Shi Zheng
              &amp; Bin Luo. Joint graph regularized dictionary learning and
              sparse ranking for multi-modal multi-shot person
              re-identification[J]. Pattern Recognition, 2020, 104: 107352. (SCI
              一区)<a
                href="pdf/2020/2020-PR-Joint%20graph%20regularized%20dictionary%20learning%20and%20sparse%20ranking%20for%20multi-modal%20multi-shot%20person%20re-identification.pdf"
                >[PDF]</a
              ><a
                target="_blank"
                rel="noopener"
                href="https://github.com/ttaalle/Lhc"
                >[CODE]</a
              >
            </p>
            <p>
              [4] <b>Aihua Zheng</b>, Naipeng Ye, Chenglong Li*, XiaoWang &amp;
              Jin Tang. Multi-modal Foreground Detection via  Inter-and
              Intra-Modality-Consistent Low-Rank Separation[J]. Neurocomputing,
              2020, 371: 27-38. (SCI 二区)<a
                href="pdf/2020/2020-NC-multi-modal%20motion%20detection.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [5] <b>Aihua Zheng</b>, Xianmin Lin, Jiacheng Dong, Wenzhong
              Wang*, Jin Tang &amp; Bin Luo. Multi-scale attention vehicle
              re-identification[J]. Neural Computing and Applications, 2020,32:
              17489-17503. (SCI 二区)<a
                href="pdf/2020/2020-NCA-Multi-scale%20attention%20vehicle%20re-identification.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [6] Hao Zhu, Huaibo Huang, Yi Li, <b>Aihua Zheng</b> &amp; Ran
              He*. Arbitrary Talking Face Generation via Attentional
              Audio-Visual Coherence Learning[C]. International Joint Conference
              on Artificial Intelligence, 2020, 4: 2362-2368.
              (CCF推荐A类国际会议)<a
                href="pdf/2020/2020-ijcai20-Talking%20Face%20Generation.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [7] Xianmin Lin, Shengwang Peng, Zhiqi Ma, Xiaoyi Zhou &amp;
              <b>Aihua Zheng*</b>. Occlusion Based Discriminative Feature Mining
              for Vehicle Re-identification[C]//International Conference of
              Pioneering Computer Scientists, Engineers and Educators.2020:
              246-257. (EI)<a
                href="pdf/2020/2020-ICPCSEE-Occlusion%EF%BF%BDsed%25Discriminative%EF%BF%BDature%25Mining%25for%25Vehicle%25Re-identification.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [8] <b>郑爱华</b>, 曾小强, 江波*, 黄岩, 汤进.
              基于局部异质协同双路网络的跨模态行人重识别[J]. 模式识别与人工智能,
              2020, 33(10): 867-878. (EI，国内权威期刊)<a
                href="pdf/2020/2020-%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E4%B8%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-%E5%9F%BA%E4%BA%8E%E5%B1%80%E9%83%A8%E5%BC%82%E8%B4%A8%E5%8D%8F%E5%90%8C%E5%8F%8C%E8%B7%AF%E7%BD%91%E7%BB%9C%E7%9A%84%E8%B7%A8%E6%A8%A1%E6%80%81%E8%A1%8C%E4%BA%BA%E9%87%8D%E8%AF%86%E5%88%AB.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [9] <b>Aihua Zheng</b>, Naipeng Ye, Xiao Wang &amp; Xiao Song*.
              3R: Word and Phoneme Edition based Data Augmentation for Lexical
              Punctuation Prediction[C]//2020 16th International Conference on
              Computational Intelligence and Security. 2020: 1-5. (EI)<a
                href="pdf/2020/2020-CIS-3R%20Word%20and%20Phoneme%20Edition%20based%20Data%20Augmentation%20for%20Lexical%20Punctuation%20Prediction.pdf"
                >[PDF]</a
              >
            </p>
            <h2 id="2019">
              <a href="#2019" class="headerlink" title="2019"></a>2019
            </h2>
            <p>
              [1] <b>Aihua Zheng</b>, Tian Zou, Yumiao Zhao, Bo Jiang, Jin Tang
              &amp; Chenglong Li*. Background subtraction with multi-scale
              structured low-rank and sparse factorization[J]. Neurocomputing,
              2019, 328: 113-121. (SCI 二区)<a
                href="pdf/2019/2019-Background%20subtraction%20with%20multi-scale%20structured%20low-rank%20and%20sparse%20factorization.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [2] Rui Wang, Huaibo Huang, Xufeng Zhang, Jixin Ma &amp;
              <b>Aihua Zheng*</b>. A Novel Distance Learning for Elastic
              Cross-Modal Audio-Visual Matching[C]//IEEE International
              Conference on Multimedia &amp; Expo Workshops. 2019: 300-305.
              (EI,最佳学生论文奖)<a
                href="pdf/2019/2019-A%20Novel%20Distance%20Learning%20for%20Elastic%20Cross-Modal%20Audio-Visual%20Matching.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [3] Cheng Long Li, Andong Lu, <b>Aihua Zheng</b>, Zhengzheng Tu
              &amp; Jin Tang*. Multi-Adapter RGBT Tracking[C]//ICCV Workshops.
              2019: 2262-2270. (EI)<a
                href="pdf/2019/2019-Multi-Adapter%20RGBT%20Tracking.pdf"
                >[PDF]</a
              >
            </p>
            <h2 id="2018">
              <a href="#2018" class="headerlink" title="2018"></a>2018
            </h2>
            <p>
              [1] <b>Aihua Zheng</b>, Foqin Wang, Amir Hussain, Jin Tang &amp;
              Bo Jiang*. Spatial-temporal representatives selection and weighted
              patch descriptor for person re-identification[J]. Neurocomputing,
              2018, 290: 121-129. (SCI 二区)<a
                href="pdf/2018/2018-NC-Spatial-temporal%20representatives%20selection%20and%20weighted%20patch%20descriptor%20for%20person%20re-identification.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [2] <b>Aihua Zheng</b>, Hongchao Li, Jiang Bo*, Chenglong Li, Jin
              Tang &amp; Bin Luo. Non-negative Dual Graph Regularized Sparse
              Ranking for Multi-shot Person Re-identification[C]//Chinese
              Conference on Pattern Recognition and Computer Visions. 2018:
              108-120. (EI)<a
                href="pdf/2018-PRCV-Non-negative%20Dual%20Graph%20Regularized.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [3] <b>Aihua Zheng</b>, Yumiao Zhao, Chenglong Li*, Jin Tang &amp;
              Bin Luo. Multispectral foreground detection via robust cross-modal
              low-rank decomposition[C]//Pacific Rim Conference on Multimedia.
              2018: 819-829. (EI, CCF推荐C类会议)<a
                href="pdf/2018/2018-PCM-Multispectral%20Foreground%20Detection%20via%20Robust%20Cross-Modal%20Low-Rank%20Decomposition.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [4] <b>Aihua Zheng</b>, Yumiao Zhao, Chenglong Li*, Jin Tang &amp;
              Bin Luo. Moving Object Detection via Robust Low-Rank and Sparse
              Separating with High-Order Structural Constraint[C]//2018 IEEE
              Fourth International Conference on Multimedia Big Data. 2018: 1-6.
              (EI)<a
                href="pdf/2018/2018-BigMM-Moving%20Object%20Detection%20via%20Robust%20Low-Rank.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [5] Dengdi Sun, Lidan Liu, <b>Aihua Zheng*</b>, Bo Jiang &amp; Bin
              Luo. Visual Cognition Inspired Vehicle Re-identification
              via Correlative Sparse Ranking with Multi-view Deep
              Features[C]//International Conference on Brain Inspired Cognitive
              Systems. 2018: 54-63. (EI)<a
                href="pdf/2018/2018-Visual%20Cognition%20Inspired%20Vehicle%20Re-identification%20via%20Correlative%20Sparse%20Ranking%20with%20Multi-view%20Deep%20Features.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [6] Ran Zhong, Wenzhong Wang, Chenglong Li,
              <b>Aihua Zheng</b> &amp; Jin Tang*. Exploring Scene Geometry for
              Scale Adaptive Object Tracking in Surveillance Videos[C]//IEEE
              International Conference on Image Processing.2018: 4113-4117. (EI,
              CCF推荐C类会议)<a
                href="pdf/2018/2018-Exploring%20Scene%20Geometry%20for%20Scale%20Adaptive%20Object%20Tracking%20in%20Surveillance%20Videos.pdf"
                >[PDF]</a
              >
            </p>
            <h2 id="2017">
              <a href="#2017" class="headerlink" title="2017"></a>2017
            </h2>
            <p>
              [1] <b>Aihua Zheng</b>, Minhe Xu, Bin Luo, Zhili Zhou &amp;
              Chenglong Li*. CLASS: Collaborative Low-Rank and Sparse Separation
              for Moving Object Detection[J]. Cognitive Computation, 2017, 9(2):
              180-193. (SCI 三区)<a
                href="pdf/2017/2017-CLASS%20Collaborative%20Low-Rank%20and%20Sparse%20Separation%20for%20Moving%20Object%20Detection.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [2] <b>Aihua Zheng</b>, Lei Zhang, Wei Zhang, Chenglong Li*, Jin
              Tang &amp; Bin Luo. Local-to-global background modeling for moving
              object detection from non-static cameras[J]. Multimedia Tools
              &amp; Applications, 2017, 76(8): 11003-11019. (SCI 三区)<a
                href="pdf/2017/2017-MTAP-Local-to-global%20background%20modeling%20for%20moving%20object%20detection%20from%20non-static%20cameras.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [3] Foqin Wang, Xuehan Zhang, Jixin Ma, Jin Tang &amp;
              <b>Aihua Zheng*</b>. Manifold ranking weighted local maximal
              occurrence descriptor for person
              re-identification[C]//International Conference on Software
              Engineering Research, Management and Applications. 2017:111-114.
              (EI,最佳论文奖)<a
                href="pdf/2017/2017-SERA-Manifold%20Ranking%20Weighted%20Local%20Maximal%20Occurrence%20Descriptor%20for%20Person%20Re-identification.pdf"
                >[PDF]</a
              >
            </p>
            <p>
              [4] Minghe Xu, Chenglong Li, Hanqin Shi, Jin Tang &amp;
              <b>Aihua Zheng*</b>. Moving object detection via integrating
              spatial compactness and appearance consistency in the low-rank
              representation[C]//CCF Chinese Conference on Computer Vision.
              2017: 50-60. (EI)<a
                href="pdf/2017/2017-CCCV-moving%20object%20detection.pdf"
                >[PDF]</a
              >
            </p>
          </div>
        </div>
      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        <div class="copyright">
          &copy;
          <span itemprop="copyrightYear">2024</span>
          <span class="with-love">
            <i class="fa fa-heart"></i>
          </span>
          <span class="author" itemprop="copyrightHolder">Zhengzheng Tu</span>
        </div>
        <div class="powered-by">
          Powered by
          <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> &
          <a href="https://theme-next.js.org/" rel="noopener" target="_blank"
            >NexT.Gemini</a
          >
        </div>
      </div>
    </footer>

    <script
      src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"
      integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY="
      crossorigin="anonymous"
    ></script>
    <script src="/js/comments.js"></script>
    <script src="/js/utils.js"></script>
    <script src="/js/motion.js"></script>
    <script src="/js/next-boot.js"></script>
  </body>
</html>
